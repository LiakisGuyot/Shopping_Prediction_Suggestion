{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importation des librairies et transformation des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940da05dd915cfd3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OneHotEncoder, LabelEncoder\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\pandas\\__init__.py:60\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     51\u001B[0m     get_option,\n\u001B[0;32m     52\u001B[0m     set_option,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     56\u001B[0m     options,\n\u001B[0;32m     57\u001B[0m )\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# let init-time option registration happen\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig_init\u001B[39;00m  \u001B[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# dtype\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     ArrowDtype,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    124\u001B[0m     DataFrame,\n\u001B[0;32m    125\u001B[0m )\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparseDtype\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1178\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1149\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:936\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1032\u001B[0m, in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:1130\u001B[0m, in \u001B[0;36mget_data\u001B[1;34m(self, path)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "#Chargement du dataframe\n",
    "df_customer = pd.read_csv('./csv/shopping_behavior_updated.csv', sep=\";\")\n",
    "\n",
    "#On regroupe notre dataframe en fonction des colonnes Age, Gender, Location, Subscription Status, Frequency of Purchases\n",
    "df_customer_info_grouped = df_customer.groupby(['Age','Gender', 'Location', 'Subscription Status','Frequency of Purchases'])\n",
    "\n",
    "def group_values (series):\n",
    "    return list(series)\n",
    "#On regroupe les produits achetés par les clients\n",
    "aggregated_product = df_customer_info_grouped['Item Purchased'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "\n",
    "#On créer notre dataframe correspondant au regroupement des produits achetés par les clients\n",
    "df_grouped_customer_purchase = pd.DataFrame(aggregated_product)\n",
    "\n",
    "print(\"Aggregated product\")\n",
    "print(df_grouped_customer_purchase)\n",
    "\n",
    "df_grouped_customer_purchase.to_csv('./csv/grouped_customer_purchase.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:09:38.981138400Z",
     "start_time": "2024-02-19T10:09:35.728997700Z"
    }
   },
   "id": "3397b8b9ece1ecd0",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création de la table des produits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b858287d3c85f102"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#On récupère l'ensemble des valeurs unique des produits\n",
    "u_products = df_grouped_customer_purchase['Item Purchased'].str.split(', ', expand = True).stack().unique()\n",
    "\n",
    "#On créer un dictionnaire qui représente la table d'achats des produits\n",
    "data = {}\n",
    "\n",
    "#On modifie la valeur stocké si le client a acheté ce produit\n",
    "for i, row in df_grouped_customer_purchase.iterrows():\n",
    "    items = row['Item Purchased'].split(', ')\n",
    "    for item in items:\n",
    "        if item not in data:\n",
    "            data[item] = [0] * len(df_grouped_customer_purchase)\n",
    "        data[item][i] += 1\n",
    "df_product_table = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df_product_table)\n",
    "df_product_table.to_csv('./csv/product_table.csv', sep=';', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:09:38.983138700Z",
     "start_time": "2024-02-19T10:09:38.981138400Z"
    }
   },
   "id": "11a686d543500ea4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encodage des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d76f647bb3ed3f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Indexe des colonnes catégorielles (Gender,Location, Subscription Status, Frequency of Purchases)\n",
    "cols_cat_info = [1,2,3,4]\n",
    "\n",
    "#On créer une copie de notre dataframe source\n",
    "df_grouped_customer = df_grouped_customer_purchase.copy()\n",
    "\n",
    "#On supprime la colonne des achats\n",
    "df_grouped_customer = df_grouped_customer.drop(columns=['Item Purchased'])\n",
    "a_grouped_customer = df_grouped_customer.values\n",
    "#Encodage des colonnes catégorielles\n",
    "label_encoders_info = [LabelEncoder() for _ in range(len(cols_cat_info))]\n",
    "for i, col_idx in enumerate(cols_cat_info):\n",
    "    a_grouped_customer[:, col_idx] = label_encoders_info[i].fit_transform(a_grouped_customer[:, col_idx])\n",
    "    \n",
    "#Print des données encodées\n",
    "print(a_grouped_customer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T10:09:38.982640300Z"
    }
   },
   "id": "4b9d21ccd62a4247",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialisation du modèle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87a275aa1f18caa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "a_product_table = df_product_table.values\n",
    "#Initialisation du modèle\n",
    "chained_model = RegressorChain(RandomForestRegressor(n_estimators=100, random_state=1), random_state=1)\n",
    "chained_model.fit(a_grouped_customer, a_product_table)\n",
    "\n",
    "y_pred = chained_model.predict(a_grouped_customer)\n",
    "print(\"MSE : \",mean_squared_error(a_product_table, y_pred))\n",
    "print(y_pred[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:09:38.989156500Z",
     "start_time": "2024-02-19T10:09:38.985142200Z"
    }
   },
   "id": "37edc55ae502642e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def run_regressor_chain_estimators(estimators, X, y):\n",
    "    \"\"\"\n",
    "    Teste différents base estimators avec une RegressorChain et retourne les scores.\n",
    "\n",
    "    Args:\n",
    "    - estimators: Dictionnaire contenant les noms et les base estimators à tester.\n",
    "    - X: Tableau NumPy des caractéristiques des clients.\n",
    "    - y: Tableau NumPy des cibles (achats de produits).\n",
    "\n",
    "    Returns:\n",
    "    - best_estimator: Meilleur base estimator obtenu avec le score correspondant.\n",
    "    \"\"\"\n",
    "\n",
    "    all_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for clf_name, clf in estimators.items():\n",
    "        start = time.time()\n",
    "\n",
    "        # Créez le modèle RegressorChain avec le base_estimator actuel et spécifiez le nombre de folds\n",
    "        chain = RegressorChain(base_estimator=clf, cv=2, random_state=1)\n",
    "\n",
    "        # Effectuez la validation croisée\n",
    "        cv_results = cross_validate(chain, X, y, scoring='neg_mean_squared_error', return_train_score=False, cv=kf, n_jobs=-1)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Stockez les résultats dans all_scores\n",
    "        all_scores.append([clf, np.mean(cv_results['test_score']), np.mean(cv_results['fit_time'])])\n",
    "        \n",
    "        # Affichez les résultats pour le modèle actuel\n",
    "        print(f\"Base estimator: {clf_name}\")\n",
    "        print(f\"Mean MSE : {np.mean(cv_results['test_score']):.3f}\")\n",
    "        print(f\"Mean fit time: {np.mean(cv_results['fit_time']):.3f} seconds\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    # Trouvez le meilleur base estimator en fonction du score moyen\n",
    "    all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_estimator = all_scores[0][0]\n",
    "    best_score = all_scores[0][1]\n",
    "    best_fit_time = all_scores[0][2]\n",
    "\n",
    "    print(\"Best base estimator is:\", best_estimator)\n",
    "    print(\"with a mean MSE of =\", best_score)\n",
    "    print(\"and a mean fit time of =\", best_fit_time, \"seconds\")\n",
    "\n",
    "    return best_estimator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T10:09:38.986644900Z"
    }
   },
   "id": "7e4b1ab5966676de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Liste des base estimators à tester\n",
    "base_estimators = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=100,random_state=1, max_depth=5),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(random_state=1),\n",
    "    'ElasticNet': ElasticNet(random_state=1),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=1),\n",
    "    'XGBRegressor': XGBRegressor(n_estimators=100,random_state=1),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=100,random_state=1),\n",
    "}\n",
    "\n",
    "# Utilisez la fonction run_regressor_chain_estimators avec la liste de base estimators\n",
    "best_estimator = run_regressor_chain_estimators(base_estimators, a_grouped_customer, a_product_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T10:09:38.989156500Z"
    }
   },
   "id": "e7957aad3c87dbae",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lasso"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d92ae8c26b5f955c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "# Créer un pipeline avec la RegressorChain et le modèle Lasso\n",
    "pipeline = Pipeline([\n",
    "    ('chain', RegressorChain(base_estimator=Lasso()))\n",
    "])\n",
    "\n",
    "# Définissez les hyperparamètres que vous souhaitez optimiser\n",
    "param_grid = {\n",
    "    'chain__base_estimator__alpha': [0.001, 0.01, 0.1, 1.0],  # Valeurs à tester pour le paramètre d'ajustement alpha\n",
    "    'chain__base_estimator__max_iter': [100, 500, 1000]  # Nombre maximum d'itérations\n",
    "}\n",
    "\n",
    "# Initialisez l'objet GridSearchCV avec le pipeline et les hyperparamètres à optimiser\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Entraînez le modèle avec la recherche par grille\n",
    "grid_search.fit(a_grouped_customer,a_product_table)\n",
    "\n",
    "# Affichez les meilleurs hyperparamètres et la meilleure MSE\n",
    "print(\"Meilleurs hyperparamètres:\", grid_search.best_params_)\n",
    "print(\"Meilleure MSE:\", grid_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T10:09:38.999668500Z",
     "start_time": "2024-02-19T10:09:38.990654Z"
    }
   },
   "id": "4d686fa1a0241252",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création de la pipeline finale mise en place d'un pickle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c579db3f98664340"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pipeline = Pipeline([\n",
    "    ('chain', RegressorChain(base_estimator=Lasso(alpha=0.001, max_iter=100)))\n",
    "])\n",
    "\n",
    "pipeline.fit(a_grouped_customer,a_product_table)\n",
    "prediction = pipeline.predict(a_grouped_customer)\n",
    "print(\"MSE : \",mean_squared_error(a_product_table, prediction))\n",
    "\n",
    "with open('./pickles/predictionModel.pkl', 'wb') as f:\n",
    "    pk.dump(pipeline, f)\n",
    "    \n",
    "#test du pickle\n",
    "with open('./pickles/predictionModel.pkl', 'rb') as f:\n",
    "    model = pk.load(f)\n",
    "    prediction = model.predict(a_grouped_customer)\n",
    "    print(\"MSE : \",mean_squared_error(a_product_table, prediction))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T10:09:38.992152200Z"
    }
   },
   "id": "7857c018993caf03",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
