{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importation des librairies et transformation des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940da05dd915cfd3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated product\n",
      "      Age  Gender    Location Subscription Status Frequency of Purchases  \\\n",
      "0      18  Female      Alaska                  No                 Weekly   \n",
      "1      18  Female    Illinois                  No            Fortnightly   \n",
      "2      18  Female      Kansas                  No               Annually   \n",
      "3      18  Female    Kentucky                  No            Fortnightly   \n",
      "4      18  Female    Maryland                  No               Annually   \n",
      "...   ...     ...         ...                 ...                    ...   \n",
      "3744   70    Male       Texas                  No         Every 3 Months   \n",
      "3745   70    Male       Texas                 Yes                Monthly   \n",
      "3746   70    Male     Vermont                  No                Monthly   \n",
      "3747   70    Male     Vermont                 Yes               Annually   \n",
      "3748   70    Male  Washington                 Yes              Bi-Weekly   \n",
      "\n",
      "      Item Purchased  \n",
      "0             Shorts  \n",
      "1              Shirt  \n",
      "2              Socks  \n",
      "3               Coat  \n",
      "4              Dress  \n",
      "...              ...  \n",
      "3744          Gloves  \n",
      "3745           Shoes  \n",
      "3746  Jewelry, Jeans  \n",
      "3747           Pants  \n",
      "3748        Sneakers  \n",
      "\n",
      "[3749 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "#Chargement du dataframe\n",
    "df_customer = pd.read_csv('./csv/shopping_behavior_updated.csv', sep=\";\")\n",
    "\n",
    "#On regroupe notre dataframe en fonction des colonnes Age, Gender, Location, Subscription Status, Frequency of Purchases\n",
    "df_customer_info_grouped = df_customer.groupby(['Age','Gender', 'Location', 'Subscription Status','Frequency of Purchases'])\n",
    "\n",
    "def group_values (series):\n",
    "    return list(series)\n",
    "#On regroupe les produits achetés par les clients\n",
    "aggregated_product = df_customer_info_grouped['Item Purchased'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "\n",
    "#On créer notre dataframe correspondant au regroupement des produits achetés par les clients\n",
    "df_grouped_customer_purchase = pd.DataFrame(aggregated_product)\n",
    "\n",
    "print(\"Aggregated product\")\n",
    "print(df_grouped_customer_purchase)\n",
    "\n",
    "df_grouped_customer_purchase.to_csv('./csv/grouped_customer_purchase.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:56:59.599187600Z",
     "start_time": "2024-02-19T16:56:59.403186Z"
    }
   },
   "id": "3397b8b9ece1ecd0",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création de la table des produits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b858287d3c85f102"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Shorts  Shirt  Socks  Coat  Dress  Boots  Handbag  Sunglasses  Hat  \\\n",
      "0          1      0      0     0      0      0        0           0    0   \n",
      "1          0      1      0     0      0      0        0           0    0   \n",
      "2          0      0      1     0      0      0        0           0    0   \n",
      "3          0      0      0     1      0      0        0           0    0   \n",
      "4          0      0      0     0      1      0        0           0    0   \n",
      "...      ...    ...    ...   ...    ...    ...      ...         ...  ...   \n",
      "3744       0      0      0     0      0      0        0           0    0   \n",
      "3745       0      0      0     0      0      0        0           0    0   \n",
      "3746       0      0      0     0      0      0        0           0    0   \n",
      "3747       0      0      0     0      0      0        0           0    0   \n",
      "3748       0      0      0     0      0      0        0           0    0   \n",
      "\n",
      "      Belt  ...  Sneakers  Sweater  Pants  T-shirt  Jewelry  Skirt  Blouse  \\\n",
      "0        0  ...         0        0      0        0        0      0       0   \n",
      "1        0  ...         0        0      0        0        0      0       0   \n",
      "2        0  ...         0        0      0        0        0      0       0   \n",
      "3        0  ...         0        0      0        0        0      0       0   \n",
      "4        0  ...         0        0      0        0        0      0       0   \n",
      "...    ...  ...       ...      ...    ...      ...      ...    ...     ...   \n",
      "3744     0  ...         0        0      0        0        0      0       0   \n",
      "3745     0  ...         0        0      0        0        0      0       0   \n",
      "3746     0  ...         0        0      0        0        1      0       0   \n",
      "3747     0  ...         0        0      1        0        0      0       0   \n",
      "3748     0  ...         1        0      0        0        0      0       0   \n",
      "\n",
      "      Sandals  Hoodie  Shoes  \n",
      "0           0       0      0  \n",
      "1           0       0      0  \n",
      "2           0       0      0  \n",
      "3           0       0      0  \n",
      "4           0       0      0  \n",
      "...       ...     ...    ...  \n",
      "3744        0       0      0  \n",
      "3745        0       0      1  \n",
      "3746        0       0      0  \n",
      "3747        0       0      0  \n",
      "3748        0       0      0  \n",
      "\n",
      "[3749 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#On récupère l'ensemble des valeurs unique des produits\n",
    "u_products = df_grouped_customer_purchase['Item Purchased'].str.split(', ', expand = True).stack().unique()\n",
    "\n",
    "#On créer un dictionnaire qui représente la table d'achats des produits\n",
    "data = {}\n",
    "\n",
    "#On modifie la valeur stocké si le client a acheté ce produit\n",
    "for i, row in df_grouped_customer_purchase.iterrows():\n",
    "    items = row['Item Purchased'].split(', ')\n",
    "    for item in items:\n",
    "        if item not in data:\n",
    "            data[item] = [0] * len(df_grouped_customer_purchase)\n",
    "        data[item][i] += 1\n",
    "df_product_table = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df_product_table)\n",
    "df_product_table.to_csv('./csv/product_table.csv', sep=';', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:52:22.314815300Z",
     "start_time": "2024-02-19T16:52:22.098799900Z"
    }
   },
   "id": "11a686d543500ea4",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encodage des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d76f647bb3ed3f9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 0 1 0 6]\n",
      " [18 0 12 0 3]\n",
      " [18 0 15 0 0]\n",
      " ...\n",
      " [70 1 44 0 4]\n",
      " [70 1 44 1 0]\n",
      " [70 1 46 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#Indexe des colonnes catégorielles (Gender,Location, Subscription Status, Frequency of Purchases)\n",
    "cols_cat_info = [1,2,3,4]\n",
    "\n",
    "#On créer une copie de notre dataframe source\n",
    "df_grouped_customer = df_grouped_customer_purchase.copy()\n",
    "\n",
    "#On supprime la colonne des achats\n",
    "df_grouped_customer = df_grouped_customer.drop(columns=['Item Purchased'])\n",
    "a_grouped_customer = df_grouped_customer.values\n",
    "#Encodage des colonnes catégorielles\n",
    "label_encoders_info = [LabelEncoder() for _ in range(len(cols_cat_info))]\n",
    "for i, col_idx in enumerate(cols_cat_info):\n",
    "    a_grouped_customer[:, col_idx] = label_encoders_info[i].fit_transform(a_grouped_customer[:, col_idx])\n",
    "    \n",
    "with open('./pickles/label_encoders_info.pkl', 'wb') as f:\n",
    "    pk.dump(label_encoders_info, f)\n",
    "#Print des données encodées\n",
    "print(a_grouped_customer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:57:15.315087100Z",
     "start_time": "2024-02-19T16:57:15.214166400Z"
    }
   },
   "id": "4b9d21ccd62a4247",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialisation du modèle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87a275aa1f18caa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.006184065084022406\n",
      "[0.71 0.12 0.02 0.01 0.   0.06 0.02 0.01 0.   0.04 0.01 0.04 0.02 0.\n",
      " 0.02 0.03 0.   0.   0.01 0.02 0.03 0.07 0.   0.01 0.04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "a_product_table = df_product_table.values\n",
    "#Initialisation du modèle\n",
    "chained_model = RegressorChain(RandomForestRegressor(n_estimators=100, random_state=1), random_state=1)\n",
    "chained_model.fit(a_grouped_customer, a_product_table)\n",
    "\n",
    "y_pred = chained_model.predict(a_grouped_customer)\n",
    "print(\"MSE : \",mean_squared_error(a_product_table, y_pred))\n",
    "print(y_pred[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:52:36.433285800Z",
     "start_time": "2024-02-19T16:52:22.320331Z"
    }
   },
   "id": "37edc55ae502642e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def run_regressor_chain_estimators(estimators, X, y):\n",
    "    \"\"\"\n",
    "    Teste différents base estimators avec une RegressorChain et retourne les scores.\n",
    "\n",
    "    Args:\n",
    "    - estimators: Dictionnaire contenant les noms et les base estimators à tester.\n",
    "    - X: Tableau NumPy des caractéristiques des clients.\n",
    "    - y: Tableau NumPy des cibles (achats de produits).\n",
    "\n",
    "    Returns:\n",
    "    - best_estimator: Meilleur base estimator obtenu avec le score correspondant.\n",
    "    \"\"\"\n",
    "\n",
    "    all_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for clf_name, clf in estimators.items():\n",
    "        start = time.time()\n",
    "\n",
    "        # Créez le modèle RegressorChain avec le base_estimator actuel et spécifiez le nombre de folds\n",
    "        chain = RegressorChain(base_estimator=clf, cv=2, random_state=1)\n",
    "\n",
    "        # Effectuez la validation croisée\n",
    "        cv_results = cross_validate(chain, X, y, scoring='neg_mean_squared_error', return_train_score=False, cv=kf, n_jobs=-1)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Stockez les résultats dans all_scores\n",
    "        all_scores.append([clf, np.mean(cv_results['test_score']), np.mean(cv_results['fit_time'])])\n",
    "        \n",
    "        # Affichez les résultats pour le modèle actuel\n",
    "        print(f\"Base estimator: {clf_name}\")\n",
    "        print(f\"Mean MSE : {np.mean(cv_results['test_score']):.3f}\")\n",
    "        print(f\"Mean fit time: {np.mean(cv_results['fit_time']):.3f} seconds\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    # Trouvez le meilleur base estimator en fonction du score moyen\n",
    "    all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_estimator = all_scores[0][0]\n",
    "    best_score = all_scores[0][1]\n",
    "    best_fit_time = all_scores[0][2]\n",
    "\n",
    "    print(\"Best base estimator is:\", best_estimator)\n",
    "    print(\"with a mean MSE of =\", best_score)\n",
    "    print(\"and a mean fit time of =\", best_fit_time, \"seconds\")\n",
    "\n",
    "    return best_estimator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:52:36.441309900Z",
     "start_time": "2024-02-19T16:52:36.430737600Z"
    }
   },
   "id": "7e4b1ab5966676de",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base estimator: RandomForestRegressor\n",
      "Mean MSE : -0.045\n",
      "Mean fit time: 93.757 seconds\n",
      "\n",
      "Base estimator: LinearRegression\n",
      "Mean MSE : -0.041\n",
      "Mean fit time: 0.281 seconds\n",
      "\n",
      "Base estimator: Ridge\n",
      "Mean MSE : -0.040\n",
      "Mean fit time: 0.182 seconds\n",
      "\n",
      "Base estimator: Lasso\n",
      "Mean MSE : -0.040\n",
      "Mean fit time: 0.208 seconds\n",
      "\n",
      "Base estimator: ElasticNet\n",
      "Mean MSE : -0.040\n",
      "Mean fit time: 0.174 seconds\n",
      "\n",
      "Base estimator: SVR\n",
      "Mean MSE : -0.043\n",
      "Mean fit time: 7.100 seconds\n",
      "\n",
      "Base estimator: KNeighborsRegressor\n",
      "Mean MSE : -0.048\n",
      "Mean fit time: 1.316 seconds\n",
      "\n",
      "Base estimator: DecisionTreeRegressor\n",
      "Mean MSE : -0.097\n",
      "Mean fit time: 0.547 seconds\n",
      "\n",
      "Base estimator: XGBRegressor\n",
      "Mean MSE : -0.053\n",
      "Mean fit time: 41.146 seconds\n",
      "\n",
      "Base estimator: GradientBoostingRegressor\n",
      "Mean MSE : -0.041\n",
      "Mean fit time: 80.430 seconds\n",
      "\n",
      "\n",
      "Best base estimator is: Lasso(random_state=1)\n",
      "with a mean MSE of = -0.04010804619236314\n",
      "and a mean fit time of = 0.20820980072021483 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Liste des base estimators à tester\n",
    "base_estimators = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=100,random_state=1, max_depth=5),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(random_state=1),\n",
    "    'ElasticNet': ElasticNet(random_state=1),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=1),\n",
    "    'XGBRegressor': XGBRegressor(n_estimators=100,random_state=1),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=100,random_state=1),\n",
    "}\n",
    "\n",
    "# Utilisez la fonction run_regressor_chain_estimators avec la liste de base estimators\n",
    "best_estimator = run_regressor_chain_estimators(base_estimators, a_grouped_customer, a_product_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:56:42.189036400Z",
     "start_time": "2024-02-19T16:52:36.436805300Z"
    }
   },
   "id": "e7957aad3c87dbae",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lasso"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d92ae8c26b5f955c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres: {'chain__base_estimator__alpha': 1.0, 'chain__base_estimator__max_iter': 100}\n",
      "Meilleure MSE: -0.04011206789742218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "# Créer un pipeline avec la RegressorChain et le modèle Lasso\n",
    "pipeline = Pipeline([\n",
    "    ('chain', RegressorChain(base_estimator=Lasso()))\n",
    "])\n",
    "\n",
    "# Définissez les hyperparamètres que vous souhaitez optimiser\n",
    "param_grid = {\n",
    "    'chain__base_estimator__alpha': [0.001, 0.01, 0.1, 1.0],  # Valeurs à tester pour le paramètre d'ajustement alpha\n",
    "    'chain__base_estimator__max_iter': [100, 500, 1000]  # Nombre maximum d'itérations\n",
    "}\n",
    "\n",
    "# Initialisez l'objet GridSearchCV avec le pipeline et les hyperparamètres à optimiser\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Entraînez le modèle avec la recherche par grille\n",
    "grid_search.fit(a_grouped_customer,a_product_table)\n",
    "\n",
    "# Affichez les meilleurs hyperparamètres et la meilleure MSE\n",
    "print(\"Meilleurs hyperparamètres:\", grid_search.best_params_)\n",
    "print(\"Meilleure MSE:\", grid_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:56:46.481340900Z",
     "start_time": "2024-02-19T16:56:42.188035100Z"
    }
   },
   "id": "4d686fa1a0241252",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création de la pipeline finale mise en place d'un pickle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c579db3f98664340"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.04003727526377244\n",
      "MSE :  0.04003727526377244\n"
     ]
    }
   ],
   "source": [
    "import pickle as pk\n",
    "pipeline = Pipeline([\n",
    "    ('chain', RegressorChain(base_estimator=Lasso(alpha=0.001, max_iter=100)))\n",
    "])\n",
    "\n",
    "pipeline.fit(a_grouped_customer,a_product_table)\n",
    "prediction = pipeline.predict(a_grouped_customer)\n",
    "print(\"MSE : \",mean_squared_error(a_product_table, prediction))\n",
    "\n",
    "with open('./pickles/predictionModel.pkl', 'wb') as f:\n",
    "    pk.dump(pipeline, f)\n",
    "    \n",
    "#test du pickle\n",
    "with open('./pickles/predictionModel.pkl', 'rb') as f:\n",
    "    model = pk.load(f)\n",
    "    prediction = model.predict(a_grouped_customer)\n",
    "    print(\"MSE : \",mean_squared_error(a_product_table, prediction))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T16:56:46.556834100Z",
     "start_time": "2024-02-19T16:56:46.477821400Z"
    }
   },
   "id": "7857c018993caf03",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
