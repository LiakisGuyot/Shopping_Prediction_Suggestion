{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importation des librairies et transformation des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940da05dd915cfd3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated product\n",
      "      Age  Gender    Location Subscription Status Frequency of Purchases  \\\n",
      "0      18  Female      Alaska                  No                 Weekly   \n",
      "1      18  Female    Illinois                  No            Fortnightly   \n",
      "2      18  Female      Kansas                  No               Annually   \n",
      "3      18  Female    Kentucky                  No            Fortnightly   \n",
      "4      18  Female    Maryland                  No               Annually   \n",
      "...   ...     ...         ...                 ...                    ...   \n",
      "3744   70    Male       Texas                  No         Every 3 Months   \n",
      "3745   70    Male       Texas                 Yes                Monthly   \n",
      "3746   70    Male     Vermont                  No                Monthly   \n",
      "3747   70    Male     Vermont                 Yes               Annually   \n",
      "3748   70    Male  Washington                 Yes              Bi-Weekly   \n",
      "\n",
      "      Item Purchased  \n",
      "0             Shorts  \n",
      "1              Shirt  \n",
      "2              Socks  \n",
      "3               Coat  \n",
      "4              Dress  \n",
      "...              ...  \n",
      "3744          Gloves  \n",
      "3745           Shoes  \n",
      "3746  Jewelry, Jeans  \n",
      "3747           Pants  \n",
      "3748        Sneakers  \n",
      "\n",
      "[3749 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "#Chargement du dataframe\n",
    "df_customer = pd.read_csv('./csv/shopping_behavior_updated.csv', sep=\";\")\n",
    "\n",
    "#On regroupe notre dataframe en fonction des colonnes Age, Gender, Location, Subscription Status, Frequency of Purchases\n",
    "df_customer_info_grouped = df_customer.groupby(['Age','Gender', 'Location', 'Subscription Status','Frequency of Purchases'])\n",
    "\n",
    "def group_values (series):\n",
    "    return list(series)\n",
    "#On regroupe les produits achetés par les clients\n",
    "aggregated_product = df_customer_info_grouped['Item Purchased'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "\n",
    "#On créer notre dataframe correspondant au regroupement des produits achetés par les clients\n",
    "df_grouped_customer_purchase = pd.DataFrame(aggregated_product)\n",
    "\n",
    "print(\"Aggregated product\")\n",
    "print(df_grouped_customer_purchase)\n",
    "\n",
    "df_grouped_customer_purchase.to_csv('./csv/grouped_customer_purchase.csv', sep=';', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:09:32.909208Z",
     "start_time": "2024-02-17T17:09:32.785016100Z"
    }
   },
   "id": "3397b8b9ece1ecd0",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création de la table des produits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b858287d3c85f102"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Shorts  Shirt  Socks  Coat  Dress  Boots  Handbag  Sunglasses  Hat  \\\n",
      "0          1      0      0     0      0      0        0           0    0   \n",
      "1          0      1      0     0      0      0        0           0    0   \n",
      "2          0      0      1     0      0      0        0           0    0   \n",
      "3          0      0      0     1      0      0        0           0    0   \n",
      "4          0      0      0     0      1      0        0           0    0   \n",
      "...      ...    ...    ...   ...    ...    ...      ...         ...  ...   \n",
      "3744       0      0      0     0      0      0        0           0    0   \n",
      "3745       0      0      0     0      0      0        0           0    0   \n",
      "3746       0      0      0     0      0      0        0           0    0   \n",
      "3747       0      0      0     0      0      0        0           0    0   \n",
      "3748       0      0      0     0      0      0        0           0    0   \n",
      "\n",
      "      Belt  ...  Sneakers  Sweater  Pants  T-shirt  Jewelry  Skirt  Blouse  \\\n",
      "0        0  ...         0        0      0        0        0      0       0   \n",
      "1        0  ...         0        0      0        0        0      0       0   \n",
      "2        0  ...         0        0      0        0        0      0       0   \n",
      "3        0  ...         0        0      0        0        0      0       0   \n",
      "4        0  ...         0        0      0        0        0      0       0   \n",
      "...    ...  ...       ...      ...    ...      ...      ...    ...     ...   \n",
      "3744     0  ...         0        0      0        0        0      0       0   \n",
      "3745     0  ...         0        0      0        0        0      0       0   \n",
      "3746     0  ...         0        0      0        0        1      0       0   \n",
      "3747     0  ...         0        0      1        0        0      0       0   \n",
      "3748     0  ...         1        0      0        0        0      0       0   \n",
      "\n",
      "      Sandals  Hoodie  Shoes  \n",
      "0           0       0      0  \n",
      "1           0       0      0  \n",
      "2           0       0      0  \n",
      "3           0       0      0  \n",
      "4           0       0      0  \n",
      "...       ...     ...    ...  \n",
      "3744        0       0      0  \n",
      "3745        0       0      1  \n",
      "3746        0       0      0  \n",
      "3747        0       0      0  \n",
      "3748        0       0      0  \n",
      "\n",
      "[3749 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#On récupère l'ensemble des valeurs unique des produits\n",
    "u_products = df_grouped_customer_purchase['Item Purchased'].str.split(', ', expand = True).stack().unique()\n",
    "\n",
    "#On créer un dictionnaire qui représente la table d'achats des produits\n",
    "data = {}\n",
    "\n",
    "#On modifie la valeur stocké si le client a acheté ce produit\n",
    "for i, row in df_grouped_customer_purchase.iterrows():\n",
    "    items = row['Item Purchased'].split(', ')\n",
    "    for item in items:\n",
    "        if item not in data:\n",
    "            data[item] = [0] * len(df_grouped_customer_purchase)\n",
    "        data[item][i] += 1\n",
    "df_product_table = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df_product_table)\n",
    "df_product_table.to_csv('./csv/product_table.csv', sep=';', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:09:33.115738700Z",
     "start_time": "2024-02-17T17:09:32.892157900Z"
    }
   },
   "id": "11a686d543500ea4",
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encodage des données"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d76f647bb3ed3f9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 0 1 0 6]\n",
      " [18 0 12 0 3]\n",
      " [18 0 15 0 0]\n",
      " ...\n",
      " [70 1 44 0 4]\n",
      " [70 1 44 1 0]\n",
      " [70 1 46 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#Indexe des colonnes catégorielles (Gender,Location, Subscription Status, Frequency of Purchases)\n",
    "cols_cat_info = [1,2,3,4]\n",
    "\n",
    "#On créer une copie de notre dataframe source\n",
    "df_grouped_customer = df_grouped_customer_purchase.copy()\n",
    "\n",
    "#On supprime la colonne des achats\n",
    "df_grouped_customer = df_grouped_customer.drop(columns=['Item Purchased'])\n",
    "a_grouped_customer = df_grouped_customer.values\n",
    "#Encodage des colonnes catégorielles\n",
    "label_encoders_info = [LabelEncoder() for _ in range(len(cols_cat_info))]\n",
    "for i, col_idx in enumerate(cols_cat_info):\n",
    "    a_grouped_customer[:, col_idx] = label_encoders_info[i].fit_transform(a_grouped_customer[:, col_idx])\n",
    "    \n",
    "#Print des données encodées\n",
    "print(a_grouped_customer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:09:33.116739800Z",
     "start_time": "2024-02-17T17:09:33.096886700Z"
    }
   },
   "id": "4b9d21ccd62a4247",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialisation du modèle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87a275aa1f18caa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.006184065084022406\n",
      "[0.71 0.12 0.02 0.01 0.   0.06 0.02 0.01 0.   0.04 0.01 0.04 0.02 0.\n",
      " 0.02 0.03 0.   0.   0.01 0.02 0.03 0.07 0.   0.01 0.04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "a_product_table = df_product_table.values\n",
    "#Initialisation du modèle\n",
    "chained_model = RegressorChain(RandomForestRegressor(n_estimators=100, random_state=1), random_state=1)\n",
    "chained_model.fit(a_grouped_customer, a_product_table)\n",
    "\n",
    "y_pred = chained_model.predict(a_grouped_customer)\n",
    "print(\"MSE : \",mean_squared_error(a_product_table, y_pred))\n",
    "print(y_pred[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:09:45.475831700Z",
     "start_time": "2024-02-17T17:09:33.117740100Z"
    }
   },
   "id": "37edc55ae502642e",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def run_regressor_chain_estimators(estimators, X, y):\n",
    "    \"\"\"\n",
    "    Teste différents base estimators avec une RegressorChain et retourne les scores.\n",
    "\n",
    "    Args:\n",
    "    - estimators: Dictionnaire contenant les noms et les base estimators à tester.\n",
    "    - X: Tableau NumPy des caractéristiques des clients.\n",
    "    - y: Tableau NumPy des cibles (achats de produits).\n",
    "\n",
    "    Returns:\n",
    "    - best_estimator: Meilleur base estimator obtenu avec le score correspondant.\n",
    "    \"\"\"\n",
    "\n",
    "    all_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for clf_name, clf in estimators.items():\n",
    "        start = time.time()\n",
    "\n",
    "        # Créez le modèle RegressorChain avec le base_estimator actuel et spécifiez le nombre de folds\n",
    "        chain = RegressorChain(base_estimator=clf, cv=2, random_state=1)\n",
    "\n",
    "        # Effectuez la validation croisée\n",
    "        cv_results = cross_validate(chain, X, y, scoring='neg_mean_squared_error', return_train_score=False, cv=kf, n_jobs=-1)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Stockez les résultats dans all_scores\n",
    "        all_scores.append([clf, np.mean(cv_results['test_score']), np.mean(cv_results['fit_time'])])\n",
    "        \n",
    "        # Affichez les résultats pour le modèle actuel\n",
    "        print(f\"Base estimator: {clf_name}\")\n",
    "        print(f\"Mean MSE : {np.mean(cv_results['test_score']):.3f}\")\n",
    "        print(f\"Mean fit time: {np.mean(cv_results['fit_time']):.3f} seconds\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    # Trouvez le meilleur base estimator en fonction du score moyen\n",
    "    all_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    best_estimator = all_scores[0][0]\n",
    "    best_score = all_scores[0][1]\n",
    "    best_fit_time = all_scores[0][2]\n",
    "\n",
    "    print(\"Best base estimator is:\", best_estimator)\n",
    "    print(\"with a mean MSE of =\", best_score)\n",
    "    print(\"and a mean fit time of =\", best_fit_time, \"seconds\")\n",
    "\n",
    "    return best_estimator"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:09:45.482984800Z",
     "start_time": "2024-02-17T17:09:45.475831700Z"
    }
   },
   "id": "7e4b1ab5966676de",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base estimator: RandomForestRegressor\n",
      "Mean MSE : -0.045\n",
      "Mean fit time: 74.597 seconds\n",
      "\n",
      "Base estimator: LinearRegression\n",
      "Mean MSE : -0.041\n",
      "Mean fit time: 0.175 seconds\n",
      "\n",
      "Base estimator: Ridge\n",
      "Mean MSE : -0.040\n",
      "Mean fit time: 0.165 seconds\n",
      "\n",
      "Base estimator: Lasso\n",
      "Mean MSE : -0.040\n",
      "Mean fit time: 0.206 seconds\n",
      "\n",
      "Base estimator: ElasticNet\n",
      "Mean MSE : -0.040\n",
      "Mean fit time: 0.282 seconds\n",
      "\n",
      "Base estimator: SVR\n",
      "Mean MSE : -0.043\n",
      "Mean fit time: 7.205 seconds\n",
      "\n",
      "Base estimator: KNeighborsRegressor\n",
      "Mean MSE : -0.048\n",
      "Mean fit time: 1.305 seconds\n",
      "\n",
      "Base estimator: DecisionTreeRegressor\n",
      "Mean MSE : -0.097\n",
      "Mean fit time: 0.452 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 23\u001B[0m\n\u001B[0;32m      9\u001B[0m base_estimators \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRandomForestRegressor\u001B[39m\u001B[38;5;124m'\u001B[39m: RandomForestRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m),\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLinearRegression\u001B[39m\u001B[38;5;124m'\u001B[39m: LinearRegression(),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGradientBoostingRegressor\u001B[39m\u001B[38;5;124m'\u001B[39m: GradientBoostingRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m     20\u001B[0m }\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Utilisez la fonction run_regressor_chain_estimators avec la liste de base estimators\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m best_estimator \u001B[38;5;241m=\u001B[39m \u001B[43mrun_regressor_chain_estimators\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimators\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma_grouped_customer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma_product_table\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[46], line 29\u001B[0m, in \u001B[0;36mrun_regressor_chain_estimators\u001B[1;34m(estimators, X, y)\u001B[0m\n\u001B[0;32m     26\u001B[0m chain \u001B[38;5;241m=\u001B[39m RegressorChain(base_estimator\u001B[38;5;241m=\u001B[39mclf, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Effectuez la validation croisée\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mneg_mean_squared_error\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# Stockez les résultats dans all_scores\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[0;32m    424\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[1;32m--> 425\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscore_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscorer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    440\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    441\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    442\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    447\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Programmation\\BI\\Projet BI\\venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Liste des base estimators à tester\n",
    "base_estimators = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=100,random_state=1, max_depth=5),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(random_state=1),\n",
    "    'ElasticNet': ElasticNet(random_state=1),\n",
    "    'SVR': SVR(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=1),\n",
    "    'XGBRegressor': XGBRegressor(n_estimators=100,random_state=1),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=100,random_state=1),\n",
    "}\n",
    "\n",
    "# Utilisez la fonction run_regressor_chain_estimators avec la liste de base estimators\n",
    "best_estimator = run_regressor_chain_estimators(base_estimators, a_grouped_customer, a_product_table)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:11:22.301784900Z",
     "start_time": "2024-02-17T17:09:45.481975500Z"
    }
   },
   "id": "e7957aad3c87dbae",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lasso"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d92ae8c26b5f955c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "# Créer un pipeline avec la RegressorChain et le modèle Lasso\n",
    "pipeline = Pipeline([\n",
    "    ('chain', RegressorChain(base_estimator=Lasso()))\n",
    "])\n",
    "\n",
    "# Définissez les hyperparamètres que vous souhaitez optimiser\n",
    "param_grid = {\n",
    "    'chain__base_estimator__alpha': [0.001, 0.01, 0.1, 1.0],  # Valeurs à tester pour le paramètre d'ajustement alpha\n",
    "    'chain__base_estimator__max_iter': [100, 500, 1000]  # Nombre maximum d'itérations\n",
    "}\n",
    "\n",
    "# Initialisez l'objet GridSearchCV avec le pipeline et les hyperparamètres à optimiser\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Entraînez le modèle avec la recherche par grille\n",
    "grid_search.fit(a_grouped_customer,a_product_table)\n",
    "\n",
    "# Affichez les meilleurs hyperparamètres et la meilleure MSE\n",
    "print(\"Meilleurs hyperparamètres:\", grid_search.best_params_)\n",
    "print(\"Meilleure MSE:\", grid_search.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T17:11:22.312814800Z",
     "start_time": "2024-02-17T17:11:22.303301600Z"
    }
   },
   "id": "4d686fa1a0241252",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Création de la pipeline finale mise en place d'un pickle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c579db3f98664340"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pipeline = Pipeline([\n",
    "    ('chain', RegressorChain(base_estimator=Lasso(alpha=0.001, max_iter=100)))\n",
    "])\n",
    "\n",
    "pipeline.fit(a_grouped_customer,a_product_table)\n",
    "prediction = pipeline.predict(a_grouped_customer)\n",
    "print(\"MSE : \",mean_squared_error(a_product_table, prediction))\n",
    "\n",
    "with open('./pickles/predictionModel.pkl', 'wb') as f:\n",
    "    pk.dump(pipeline, f)\n",
    "    \n",
    "#test du pickle\n",
    "with open('./pickles/predictionModel.pkl', 'rb') as f:\n",
    "    model = pk.load(f)\n",
    "    prediction = model.predict(a_grouped_customer)\n",
    "    print(\"MSE : \",mean_squared_error(a_product_table, prediction))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-17T17:11:22.304807800Z"
    }
   },
   "id": "7857c018993caf03",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
